# -*- coding: utf-8 -*-
"""
Rakutenç«¶é¦¬ ç›£è¦–ãƒ»é€šçŸ¥ãƒãƒƒãƒï¼ˆé¨æ‰‹ãƒ©ãƒ³ã‚¯200ä½ï¼‹é¨æ‰‹åãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‹æ—¥æ¬¡ã‚µãƒãƒªï¼‰
- ä¸€è¦§ã§ç™ºèµ°æ™‚åˆ»å–å¾—
- è©³ç´°/ã‚ªãƒƒã‚º ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆRIDã‚¢ãƒ³ã‚«ãƒ¼è¿‘å‚ & ã€Œç™ºèµ°ã€æ–‡è„ˆå„ªå…ˆã€ãƒã‚¤ã‚ºèªé™¤å¤–ï¼‰
- çª“å†…1å›é€šçŸ¥ / 429ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ / Sheetæ°¸ç¶šTTL
- é€šçŸ¥å…ˆï¼šGoogleã‚·ãƒ¼ãƒˆ(ã‚¿ãƒ–A=åç§°ã€Œ1ã€)ã®Håˆ—ã‹ã‚‰ userId ã‚’åé›†
- æˆ¦ç•¥â‘¢ã¯å°‚ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆ1è»¸ãƒ»ç›¸æ‰‹10ã€œ20å€ãƒ»é¦¬ç•ªè²·ã„ç›®ãƒ»å€™è£œæœ€å¤§4é ­ãƒ»ç‚¹æ•°è¡¨ç¤ºï¼‰
- é¨æ‰‹ãƒ©ãƒ³ã‚¯(A/B/C)è¡¨ç¤ºï¼ˆA=1-70ä½, B=71-200ä½, C=ãã®ä»–ï¼‰
- ã‚¿ã‚¤ãƒˆãƒ«ã€Œã€æˆ¦ç•¥â—¯è©²å½“ãƒ¬ãƒ¼ã‚¹ç™ºè¦‹ğŸ’¡ã€‘ã€ã§çµ±ä¸€
- betsã‚·ãƒ¼ãƒˆã¸è²·ã„ç›®ï¼ˆé¦¬ç•ªï¼‰ã‚’è¨˜éŒ²
- çµ‚æ¥­æ™‚ã«å½“æ—¥åˆ†ã®ä»¶æ•°/çš„ä¸­ç‡/å›åç‡ã‚µãƒãƒªã‚’LINEé€šçŸ¥
- åˆ¸ç¨®ã¯ STRATEGY_BET_KIND_JSON ã§è¨­å®šï¼ˆæ—¢å®š: â‘ é¦¬é€£, â‘¡é¦¬å˜, â‘¢ä¸‰é€£å˜, â‘£ä¸‰é€£è¤‡ï¼‰
- â˜…NEW: å˜è¤‡ã‚ªãƒƒã‚ºè¡¨ã«é¨æ‰‹åˆ—ãŒç„¡ã„æ™‚ã€å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸ã‹ã‚‰ã€Œé¦¬ç•ªâ†’é¨æ‰‹åã€ã‚’è£œå®Œ
- â˜…NEW: é¨æ‰‹ãƒ©ãƒ³ã‚¯ã¯ãƒ™ãƒ¼ã‚¹å†…è”µ100åï¼‹ENV/Sheetã§200ä½ã¾ã§æ‹¡å¼µå¯èƒ½
"""

import os, re, json, time, random, logging, pathlib, hashlib, unicodedata
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional, Tuple, Set

import requests
from bs4 import BeautifulSoup, Tag
from strategy_rules import eval_strategy

# --- é€šçŸ¥ãƒ­ã‚° append ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ã import ---
try:
    from utils_notify_log import append_notify_log
except ModuleNotFoundError:
    import logging as _logging
    def append_notify_log(*args, **kwargs):
        _logging.warning("[WARN] utils_notify_log ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€é€šçŸ¥ãƒ­ã‚°ã®è¿½è¨˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

# æ—¥ä»˜ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
from utils_summary import jst_today_str, jst_now

# ===== Google Sheets =====
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build

# ========= åŸºæœ¬è¨­å®š =========
JST = timezone(timedelta(hours=9))
SESSION = requests.Session()
SESSION.headers.update({
    "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/124.0.0.0 Safari/537.36"),
    "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
    "Cache-Control": "no-cache",
})
TIMEOUT = (10, 25)
RETRY = 3
SLEEP_BETWEEN = (0.6, 1.2)

LINE_PUSH_URL = "https://api.line.me/v2/bot/message/push"

# ========= ç’°å¢ƒå¤‰æ•° =========
START_HOUR          = int(os.getenv("START_HOUR", "10"))
END_HOUR            = int(os.getenv("END_HOUR",   "22"))
DRY_RUN             = os.getenv("DRY_RUN", "False").lower() == "true"
KILL_SWITCH         = os.getenv("KILL_SWITCH", "False").lower() == "true"
NOTIFY_ENABLED      = os.getenv("NOTIFY_ENABLED", "1") == "1"
DEBUG_RACEIDS       = [s.strip() for s in os.getenv("DEBUG_RACEIDS", "").split(",") if s.strip()]

NOTIFY_TTL_SEC      = int(os.getenv("NOTIFY_TTL_SEC", "3600"))
NOTIFY_COOLDOWN_SEC = int(os.getenv("NOTIFY_COOLDOWN_SEC", "1800"))

WINDOW_BEFORE_MIN   = int(os.getenv("WINDOW_BEFORE_MIN", "15"))
WINDOW_AFTER_MIN    = int(os.getenv("WINDOW_AFTER_MIN", "-10"))

CUTOFF_OFFSET_MIN   = int(os.getenv("CUTOFF_OFFSET_MIN", "0"))
FORCE_RUN           = os.getenv("FORCE_RUN", "0") == "1"

LINE_ACCESS_TOKEN   = os.getenv("LINE_ACCESS_TOKEN", "")
LINE_USER_ID        = os.getenv("LINE_USER_ID", "")
LINE_USER_IDS       = [s.strip() for s in os.getenv("LINE_USER_IDS", "").split(",") if s.strip()]

GOOGLE_CREDENTIALS_JSON = os.getenv("GOOGLE_CREDENTIALS_JSON", "")
GOOGLE_SHEET_ID         = os.getenv("GOOGLE_SHEET_ID", "")

# TTLç®¡ç†ã‚¿ãƒ–ï¼ˆåå‰ or gidï¼‰
GOOGLE_SHEET_TAB        = os.getenv("GOOGLE_SHEET_TAB", "notified")

# é€ä¿¡å…ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’èª­ã‚€ã‚¿ãƒ–Aï¼ˆ=ã€Œ1ã€ï¼‰ã¨åˆ—ï¼ˆ=Hï¼‰
USERS_SHEET_NAME        = os.getenv("USERS_SHEET_NAME", "1")
USERS_USERID_COL        = os.getenv("USERS_USERID_COL", "H")

# ãƒ™ãƒƒãƒˆè¨˜éŒ²ã‚¿ãƒ–
BETS_SHEET_TAB          = os.getenv("BETS_SHEET_TAB", "bets")

# åˆ¸ç¨®ï¼ˆæˆ¦ç•¥â†’åˆ¸ç¨®ï¼‰
_DEFAULT_BET_KIND = {"1":"é¦¬é€£", "2":"é¦¬å˜", "3":"ä¸‰é€£å˜", "4":"ä¸‰é€£è¤‡"}
try:
    STRATEGY_BET_KIND = json.loads(os.getenv("STRATEGY_BET_KIND_JSON","")) or _DEFAULT_BET_KIND
except Exception:
    STRATEGY_BET_KIND = _DEFAULT_BET_KIND

UNIT_STAKE_YEN = int(os.getenv("UNIT_STAKE_YEN", "100"))  # 1ç‚¹100å††

RACEID_RE   = re.compile(r"/RACEID/(\d{18})")
TIME_PATS = [
    re.compile(r"\b(\d{1,2}):(\d{2})\b"),
    re.compile(r"\b(\d{1,2})ï¼š(\d{2})\b"),
    re.compile(r"\b(\d{1,2})\s*æ™‚\s*(\d{1,2})\s*åˆ†\b"),
]
PLACEHOLDER = re.compile(r"\d{8}0000000000$")

IGNORE_NEAR_PAT = re.compile(r"(ç¾åœ¨|æ›´æ–°|ç™ºå£²|ç· åˆ‡|æŠ•ç¥¨|ã‚ªãƒƒã‚º|ç¢ºå®š|æ‰•æˆ»|å®Ÿæ³)")
LABEL_NEAR_PAT  = re.compile(r"(ç™ºèµ°|ç™ºèµ°äºˆå®š|ç™ºèµ°æ™‚åˆ»|ç™ºé€|å‡ºèµ°)")

# ========= é¨æ‰‹ãƒ©ãƒ³ã‚¯ï¼ˆ1ã€œ200ä½ã‚’å†…è”µï¼‰ =========
def _normalize_name(s: str) -> str:
    if not s: return ""
    s = unicodedata.normalize("NFKC", s)
    return s.replace(" ", "").replace("\u3000", "")

JOCKEY_RANK_TABLE_RAW: Dict[int, str] = {
    1:"ç¬¹å·ç¿¼",2:"çŸ¢é‡è²´ä¹‹",3:"å¡šæœ¬å¾å¾",4:"å°ç‰§å¤ª",5:"å±±æœ¬è¡å“‰",6:"é‡ç•‘å‡Œ",7:"çŸ³å·å€­",8:"æ°¸æ£®å¤§æ™º",9:"ä¸­å³¶é¾ä¹Ÿ",10:"å‰åŸå¯›äºº",
    11:"åºƒç€¬èˆª",12:"åŠ è—¤è¡ä¸€",13:"æœ›æœˆæ´µè¼",14:"éˆ´æœ¨æµä»‹",15:"æ¸¡è¾ºç«œä¹Ÿ",16:"è½åˆç„å¤ª",17:"å±±å£å‹²",18:"æœ¬ç”°æ­£é‡",19:"å‰æ‘æ™ºæ´‹",20:"èµ¤å²¡ä¿®æ¬¡",
    21:"å²¡éƒ¨èª ",22:"é«˜æ¾äº®",23:"é£›ç”°æ„›æ–—",24:"è¥¿å°†å¤ª",25:"å¾¡ç¥æœ¬è¨“å²",26:"ä¸‹åŸç†",27:"å±±æœ¬æ”¿è¡",28:"ä»Šäº•è²´å¤§",29:"ç­’äº•å‹‡ä»‹",30:"å±±ç”°ç¾©è²´",
    31:"ä¸¸é‡å‹è™",32:"é’æŸ³æ­£ç¾©",33:"æ¸¡æ¥å¿ƒè·¯",34:"ä»Šäº•åƒå°‹",35:"å’Œç”°è­²æ²»",36:"äº•ä¸Šç‘›å¤ª",37:"å¤šç”°ç¾…èª ä¹Ÿ",38:"é‡‘ç”°åˆ©è²´",39:"å¡šæœ¬æ¶¼äºº",40:"å®®ä¸‹ç³",
    41:"æ —åŸå¤§æ²³",42:"è¥¿è¬™ä¸€",43:"è¥¿å•“å¤ª",44:"é•·æ¾¤å¹¸å¤ª",45:"å±±ä¸­æ‚ å¸Œ",46:"èŠæ± ä¸€æ¨¹",47:"ç”ºç”°ç›´å¸Œ",48:"çŸ³å·æ…å°†",49:"è…åŸè¾°å¾³",50:"å³¶æ´¥æ–°",
    51:"é˜¿éƒ¨é¾",52:"å°é‡æ¥“é¦¬",53:"èµ¤å¡šå¥ä»",54:"åŠ è—¤ç¿”é¦¬",55:"æ‰æµ¦å¥å¤ª",56:"å¼µç”°æ˜‚",57:"æ¡‘æ‘çœŸæ˜",58:"å±±æœ¬è¡ç´€",59:"å‰äº•ç« ",60:"å¤§ç•‘æ…§æ‚Ÿ",
    61:"æŸ´ç”°å‹‡çœŸ",62:"å¤§ç•‘é›…ç« ",63:"ç¬¹ç”°çŸ¥å®",64:"ç´°å·æ™ºå²",65:"é‡‘å±±æ˜‡é¦¬",66:"å²©æœ¬æ€œ",67:"å²¡é¼å¤ªéƒ",68:"å²¡æ‘å“å¼¥",69:"ä¸­åŸè“®",70:"è—¤æœ¬åŒ ",
    71:"é«˜æ©‹æ‚ é‡Œ",72:"åœŸæ–¹é¢¯å¤ª",73:"é•·è°·éƒ¨é§¿å¼¥",74:"é«˜æ©‹æ„›å¶",75:"åŠå·è£•ä¸€",76:"åŠ èŒ‚é£›ç¿”",77:"å·åŸæ­£ä¸€",78:"æ‘ä¸Šå¿",79:"å²¡æ‘å¥å¸",80:"ç”°é‡è±Šä¸‰",
    81:"æ‘ä¸Šå¼˜æ¨¹",82:"å±±å´èª å£«",83:"ç«¹å‰å¾¹",84:"å®®å†…å‹‡æ¨¹",85:"èˆ¹å±±è”µäºº",86:"ä¸­æ‘å¤ªé™½",87:"æœ¬æ©‹å­å¤ª",88:"å‡ºæ°´æ‹“äºº",89:"æ–°åº„æµ·èª ",90:"å±±å´é›…ç”±",
    91:"é˜¿éƒ¨æ­¦è‡£",92:"å®‰è—¤æ´‹ä¸€",93:"å°æ—å‡Œ",94:"å‹æ£®ç¿”å¤ªéƒ",95:"ç¦åŸæ",96:"å²©æ©‹å‹‡äºŒ",97:"ä½ã€…æœ¨å¿—éŸ³",98:"æœ¨ä¹‹å‰è‘µ",99:"è—¤ç”°å‡Œ",100:"ä½é‡é¥ä¹…",
    101:"äº•ä¸Šå¹¹å¤ª",102:"ä½è—¤å‹å‰‡",103:"å‰æ‘èª ä¹‹åŠ©",104:"å‰æœ¬éš†è¨˜",105:"æ¸¡è¾ºç«œä¹Ÿ",106:"å‰äº•å‹å½¦",107:"å²¡ç”°ç¥¥å—£",108:"æ¾æœ¨å¤§åœ°",109:"åŠ è—¤å’Œç¾©",110:"ç”°ä¸­å­¦",
    111:"å·å³¶æ‹“",112:"æ£®æ³°æ–—",113:"æœéƒ¨èŒ‚å²",114:"åŠ è—¤èª“äºŒ",115:"æ¿±å°šç¾",116:"æ°¸äº•å­å…¸",117:"é«˜é‡èª æ¯…",118:"å¤§ç•‘é›…ç« ",119:"å¤§å±±çœŸå¾",120:"é•·è°·éƒ¨é§¿å¼¥",
    121:"ä¸¹ç¾½å…‹è¼",122:"å±±å£å‹²äºŒ",123:"ç”°ä¸­å­¦è‰¯",124:"è½åˆç„å¤ªæœ—",125:"ç´°å·æ™ºå²æœ—",126:"æ¾æœ¬å‰›å²",127:"è—¤åŸè‰¯ä¸€",128:"å±±æœ¬æ”¿è¡è‰¯",129:"ä½åŸç§€æ³°",130:"è—¤ç”°å¼˜æ²»",
    131:"å‰ç”°æ™ƒæµ©",132:"å²¡æ‘å“å¼¥è‰¯",133:"å®®å·å®Ÿ",134:"éƒ·é–“å‹‡å¤ª",135:"ä¸Šç”°å°†å¸",136:"å€‰å…¼è‚²åº·",137:"èµ¤å²¡ä¿®äºŒ",138:"æ—è¬™ä½‘",139:"å¤šç”°ç¾…èª ä¹Ÿè‰¯",140:"æ¿±ç”°é”ä¹Ÿ",
    141:"ç•‘ä¸­ä¿¡å¸",142:"å¡šæœ¬é›„å¤§",143:"å²¡é¼å¤ªéƒè‰¯",144:"å²©æœ¬æ€œè‰¯",145:"å¤§å±±é¾å¤ªéƒ",146:"ä½ã€…æœ¨å›½æ˜",147:"æ± è°·åŒ ç¿”",148:"ä½ã€…æœ¨ä¸–éº—",149:"å±±ç”°é›„å¤§",150:"ç”°ä¸­å­¦å¤§",
    151:"ä¸­è¶Šç‰ä¸–",152:"æ¿±ç”°é”ä¹Ÿè‰¯",153:"å¤§ä¹…ä¿å‹é›…",154:"å°è°·å‘¨å¹³",155:"å¤§æŸ¿ä¸€çœŸ",156:"é•·è°·éƒ¨é§¿ä¹Ÿ",157:"ç”°æ‘ç›´ä¹Ÿ",158:"çŸ³å ‚éŸ¿",159:"ç«¹æ‘é”ä¹Ÿ",160:"é´¨å®®ç¥¥è¡Œ",
    161:"æ‰æµ¦å¥å¤ªè‰¯",162:"ä¸‹åŸç†è‰¯",163:"ç”°ä¸­æ´¸å¤š",164:"é•·ç”°é€²ä»",165:"å¤§å±±çœŸå¾è‰¯",166:"æ¸¡è¾ºè–«å½¦",167:"å²¡ç”°ç¥¥å—£è‰¯",168:"å‰äº•ç« è‰¯",169:"æ¾æœ¨å¤§åœ°è‰¯",170:"ç¬¹ç”°çŸ¥å®è‰¯",
    171:"äº•ä¸Šç‘›å¤ªè‰¯",172:"å»£ç€¬èˆª",173:"ç”°æ‘ç›´ä¹Ÿè‰¯",174:"çŸ³å ‚éŸ¿è‰¯",175:"å°è°·å‘¨å¹³è‰¯",176:"ä¸­ç”°è²´å£«",177:"å¤§æŸ¿ä¸€çœŸè‰¯",178:"ç”°ä¸­å­¦éš†",179:"æ°¸äº•å­å…¸è‰¯",180:"æ‰æµ¦å¥å¤ªæœ—",
    181:"ç«¹æ‘é”ä¹Ÿè‰¯",182:"é´¨å®®ç¥¥è¡Œè‰¯",183:"æ¾æœ¬å‰›å²è‰¯",184:"å°ç‰§å¤ªè‰¯",185:"å‰æ‘æ™ºæ´‹è‰¯",186:"ä¸‹åŸç†éš†",187:"å»£ç€¬èˆªè‰¯",188:"é•·è°·éƒ¨é§¿å¼¥è‰¯",189:"ä¸­è¶Šç‰ä¸–è‰¯",190:"ç”°ä¸­å­¦çœŸ",
    191:"é•·ç”°é€²ä»è‰¯",192:"ä½åŸç§€æ³°è‰¯",193:"å¤§æŸ¿ä¸€çœŸéš†",194:"é«˜é‡èª æ¯…è‰¯",195:"å±±ç”°é›„å¤§è‰¯",196:"æ± è°·åŒ ç¿”è‰¯",197:"å°ç‰§å¤ªéš†",198:"çŸ³å·æ…å°†è‰¯",199:"å‰æ‘èª ä¹‹åŠ©è‰¯",200:"å±±æœ¬è¡å“‰è‰¯",
}
_JOCKEY_NAME_TO_RANK: Dict[str, int] = { _normalize_name(v): k for k, v in JOCKEY_RANK_TABLE_RAW.items() }

def jockey_rank_letter_by_name(name: Optional[str]) -> str:
    if not name: return "â€”"
    rank = _JOCKEY_NAME_TO_RANK.get(_normalize_name(name))
    if rank is None: return "C"
    if 1 <= rank <= 70: return "A"
    if 71 <= rank <= 200: return "B"
    return "C"

# ========= å…±é€š =========
def now_jst() -> datetime: return datetime.now(JST)
def within_operating_hours() -> bool:
    if FORCE_RUN: return True
    return START_HOUR <= now_jst().hour < END_HOUR

def fetch(url: str) -> str:
    last_err = None
    for i in range(1, RETRY + 1):
        try:
            r = SESSION.get(url, timeout=TIMEOUT)
            r.raise_for_status()
            r.encoding = "utf-8"
            return r.text
        except Exception as e:
            last_err = e
            wait = random.uniform(*SLEEP_BETWEEN)
            logging.warning(f"[WARN] fetchå¤±æ•—({i}/{RETRY}) {e} -> {wait:.1f}så¾…æ©Ÿ: {url}")
            time.sleep(wait)
    raise last_err

# ========= Google Sheets =========
def _sheet_service():
    if not GOOGLE_CREDENTIALS_JSON or not GOOGLE_SHEET_ID:
        raise RuntimeError("Google Sheets ã®ç’°å¢ƒå¤‰æ•°ä¸è¶³")
    info = json.loads(GOOGLE_CREDENTIALS_JSON)
    creds = Credentials.from_service_account_info(info, scopes=["https://www.googleapis.com/auth/spreadsheets"])
    return build("sheets", "v4", credentials=creds, cache_discovery=False)

def _resolve_sheet_title(svc, tab_or_gid: str) -> str:
    """åå‰ or gid ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã«æ­£è¦åŒ–ã€‚ãªã‘ã‚Œã°ä½œæˆ"""
    tab = tab_or_gid
    meta = svc.spreadsheets().get(spreadsheetId=GOOGLE_SHEET_ID).execute()
    sheets = meta.get("sheets", [])
    if tab.isdigit() and len(tab) > 3:
        gid = int(tab)
        for s in sheets:
            if s["properties"]["sheetId"] == gid:
                return s["properties"]["title"]
        raise RuntimeError(f"æŒ‡å®šgidã®ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {gid}")
    for s in sheets:
        if s["properties"]["title"] == tab:
            return tab
    body = {"requests": [{"addSheet": {"properties": {"title": tab}}}]}
    svc.spreadsheets().batchUpdate(spreadsheetId=GOOGLE_SHEET_ID, body=body).execute()
    return tab

def _sheet_get_range_values(svc, title: str, a1: str) -> List[List[str]]:
    res = svc.spreadsheets().values().get(spreadsheetId=GOOGLE_SHEET_ID, range=f"'{title}'!{a1}").execute()
    return res.get("values", [])

def _sheet_update_range_values(svc, title: str, a1: str, values: List[List[str]]):
    svc.spreadsheets().values().update(
        spreadsheetId=GOOGLE_SHEET_ID, range=f"'{title}'!{a1}",
        valueInputOption="RAW", body={"values": values}
    ).execute()

def sheet_load_notified() -> Dict[str, float]:
    svc = _sheet_service()
    title = _resolve_sheet_title(svc, GOOGLE_SHEET_TAB)
    values = _sheet_get_range_values(svc, title, "A:C")
    start = 1 if values and values[0] and str(values[0][0]).upper() in ("KEY","RACEID","RID","ID") else 0
    d: Dict[str, float] = {}
    for row in values[start:]:
        if not row or len(row) < 2: continue
        key = str(row[0]).strip()
        try: d[key] = float(row[1])
        except: pass
    return d

def sheet_upsert_notified(key: str, ts: float, note: str = "") -> None:
    svc = _sheet_service()
    title = _resolve_sheet_title(svc, GOOGLE_SHEET_TAB)
    values = _sheet_get_range_values(svc, title, "A:C")
    header = ["KEY","TS_EPOCH","NOTE"]
    if not values:
        _sheet_update_range_values(svc, title, "A:C", [header, [key, ts, note]]); return
    start_row = 1 if values and values[0] and values[0][0] in header else 0
    found = None
    for i, row in enumerate(values[start_row:], start=start_row):
        if row and str(row[0]).strip() == key:
            found = i; break
    if found is None:
        values.append([key, ts, note])
    else:
        values[found] = [key, ts, note]
    _sheet_update_range_values(svc, title, "A:C", values)

# ========= é€ä¿¡å…ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ =========
def load_user_ids_from_simple_col() -> List[str]:
    svc = _sheet_service()
    title = USERS_SHEET_NAME
    col = USERS_USERID_COL.upper()
    values = _sheet_get_range_values(svc, title, f"{col}:{col}")
    user_ids: List[str] = []
    for i, row in enumerate(values):
        v = (row[0].strip() if row and row[0] is not None else "")
        if not v: continue
        low = v.replace(" ","").lower()
        if i == 0 and ("userid" in low or "user id" in low or "line" in low): continue
        if not v.startswith("U"): continue
        if v not in user_ids: user_ids.append(v)
    logging.info("[INFO] usersã‚·ãƒ¼ãƒˆèª­è¾¼: %dä»¶ from tab=%s", len(user_ids), title)
    return user_ids

# ========= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
def _extract_raceids_from_soup(soup: BeautifulSoup) -> List[str]:
    rids: List[str] = []
    for a in soup.find_all("a", href=True):
        m = RACEID_RE.search(a["href"])
        if m:
            rid = m.group(1)
            if not PLACEHOLDER.search(rid):
                rids.append(rid)
    return sorted(set(rids))

def _rid_date_parts(rid: str) -> Tuple[int,int,int]:
    return int(rid[0:4]), int(rid[4:6]), int(rid[6:8])

def _norm_hhmm_from_text(text: str) -> Optional[Tuple[int,int,str]]:
    if not text: return None
    s = str(text)
    for pat, tag in zip(TIME_PATS, ("half","full","kanji")):
        m = pat.search(s)
        if m:
            hh = int(m.group(1)); mm = int(m.group(2))
            if 0<=hh<=23 and 0<=mm<=59: return hh, mm, tag
    return None

def _make_dt_from_hhmm(rid: str, hh: int, mm: int) -> Optional[datetime]:
    try:
        y, mon, d = _rid_date_parts(rid)
        return datetime(y, mon, d, hh, mm, tzinfo=JST)
    except: return None

def _find_time_nearby(el: Tag) -> Tuple[Optional[str], str]:
    t = el.find("time")
    if t:
        for attr in ("datetime","data-time","title","aria-label"):
            v = t.get(attr)
            if v:
                got = _norm_hhmm_from_text(v)
                if got: hh,mm,why=got; return f"{hh:02d}:{mm:02d}", f"time@{attr}/{why}"
        got = _norm_hhmm_from_text(t.get_text(" ", strip=True))
        if got: hh,mm,why=got; return f"{hh:02d}:{mm:02d}", f"time@text/{why}"
    for node in el.find_all(True, recursive=True):
        for attr in ("data-starttime","data-start-time","data-time","title","aria-label"):
            v = node.get(attr)
            if not v: continue
            got = _norm_hhmm_from_text(v)
            if got: hh,mm,why=got; return f"{hh:02d}:{mm:02d}", f"data:{attr}/{why}"
    for sel in [".startTime",".cellStartTime",".raceTime",".time",".start-time"]:
        node = el.select_one(sel)
        if node:
            got = _norm_hhmm_from_text(node.get_text(" ", strip=True))
            if got: hh,mm,why=got; return f"{hh:02d}:{mm:02d}", f"sel:{sel}/{why}"
    got = _norm_hhmm_from_text(el.get_text(" ", strip=True))
    if got: hh,mm,why=got; return f"{hh:02d}:{mm:02d}", f"row:text/{why}"
    return None, "-"

# ========= ç™ºèµ°æ™‚åˆ»ï¼ˆä¸€è¦§ãƒšãƒ¼ã‚¸ï¼‰è§£æ =========
def parse_post_times_from_table_like(root: Tag) -> Dict[str, datetime]:
    post_map: Dict[str, datetime] = {}
    # ãƒ†ãƒ¼ãƒ–ãƒ«
    for table in root.find_all("table"):
        thead = table.find("thead")
        if thead:
            head_text = "".join(thead.stripped_strings)
            if not any(k in head_text for k in ("ç™ºèµ°","ç™ºèµ°æ™‚åˆ»","ãƒ¬ãƒ¼ã‚¹")): continue
        body = table.find("tbody") or table
        for tr in body.find_all("tr"):
            rid=None; link=tr.find("a", href=True)
            if link:
                m = RACEID_RE.search(link["href"])
                if m: rid=m.group(1)
            if not rid or PLACEHOLDER.search(rid): continue
            hhmm, reason = _find_time_nearby(tr)
            if not hhmm: continue
            hh,mm = map(int, hhmm.split(":"))
            dt = _make_dt_from_hhmm(rid, hh, mm)
            if dt: post_map[rid]=dt
    # ã‚«ãƒ¼ãƒ‰å‹
    for a in root.find_all("a", href=True):
        m = RACEID_RE.search(a["href"])
        if not m: continue
        rid=m.group(1)
        if PLACEHOLDER.search(rid) or rid in post_map: continue
        host=None; depth=0
        for parent in a.parents:
            if isinstance(parent, Tag) and parent.name in ("tr","li","div","section","article"):
                host=parent; break
            depth += 1
            if depth >= 6:
                break
        host = host or a
        hhmm, reason = _find_time_nearby(host)
        if not hhmm:
            sib_text=" ".join([x.get_text(" ", strip=True) for x in a.find_all_next(limit=4) if isinstance(x, Tag)])
            got=_norm_hhmm_from_text(sib_text)
            if got:
                hh,mm,why=got
                hhmm,reason=f"{hh:02d}:{mm:02d}", f"next:text/{why}"
        if not hhmm: continue
        hh,mm=map(int, hhmm.split(":"))
        dt=_make_dt_from_hhmm(rid, hh, mm)
        if dt: post_map[rid]=dt
    return post_map

def collect_post_time_map(ymd: str, ymd_next: str) -> Dict[str, datetime]:
    post_map: Dict[str, datetime] = {}
    def _merge_from(url: str):
        try:
            soup = BeautifulSoup(fetch(url), "lxml")
            post_map.update(parse_post_times_from_table_like(soup))
        except Exception as e:
            logging.warning(f"[WARN] ç™ºèµ°ä¸€è¦§èª­ã¿è¾¼ã¿å¤±æ•—: {e} ({url})")
    _merge_from(f"https://keiba.rakuten.co.jp/race_card/list/RACEID/{ymd}0000000000")
    _merge_from(f"https://keiba.rakuten.co.jp/race_card/list/RACEID/{ymd_next}0000000000")
    logging.info(f"[INFO] ç™ºèµ°æ™‚åˆ»å–å¾—: {len(post_map)}ä»¶")
    return post_map

# ========= ã‚ªãƒƒã‚ºè§£æï¼ˆå˜è¤‡ãƒšãƒ¼ã‚¸ï¼‰ =========
def _clean(s: str) -> str: return re.sub(r"\s+","", s or "")
def _as_float(text: str) -> Optional[float]:
    if not text: return None
    t = text.replace(",","").strip()
    if "%" in t or "-" in t or "ï½" in t or "~" in t: return None
    m = re.search(r"\d+(?:\.\d+)?", t); return float(m.group(0)) if m else None
def _as_int(text: str) -> Optional[int]:
    if not text: return None
    m = re.search(r"\d+", text); return int(m.group(0)) if m else None

def _find_popular_odds_table(soup: BeautifulSoup) -> Tuple[Optional[BeautifulSoup], Dict[str,int]]:
    for table in soup.find_all("table"):
        thead = table.find("thead")
        if not thead: continue
        headers = [_clean(th.get_text()) for th in thead.find_all(["th","td"])]
        if not headers: continue
        pop_idx=win_idx=num_idx=jockey_idx=None
        for i,h in enumerate(headers):
            if h in ("äººæ°—","é †ä½") or ("äººæ°—" in h and "é †" not in h): pop_idx=i; break
        win_c=[]
        for i,h in enumerate(headers):
            if ("è¤‡" in h) or ("ç‡" in h) or ("%" in h): continue
            if h=="å˜å‹": win_c.append((0,i))
            elif "å˜å‹" in h: win_c.append((1,i))
            elif "ã‚ªãƒƒã‚º" in h: win_c.append((2,i))
        win_idx = sorted(win_c, key=lambda x:x[0])[0][1] if win_c else None
        for i,h in enumerate(headers):
            if "é¦¬ç•ª" in h: num_idx=i; break
        if num_idx is None:
            for i,h in enumerate(headers):
                if ("é¦¬" in h) and ("é¦¬å" not in h) and (i!=pop_idx): num_idx=i; break
        for i,h in enumerate(headers):
            if any(k in h for k in ("é¨æ‰‹","é¨æ‰‹å")): jockey_idx=i; break
        if pop_idx is None or win_idx is None: continue
        body=table.find("tbody") or table
        rows=body.find_all("tr")
        seq_ok,last=0,0
        for tr in rows[:6]:
            tds=tr.find_all(["td","th"])
            if len(tds)<=max(pop_idx,win_idx): continue
            s=tds[pop_idx].get_text(strip=True)
            if not s.isdigit(): break
            v=int(s)
            if v<=last: break
            last=v; seq_ok+=1
        if seq_ok>=2:
            return table, {"pop":pop_idx,"win":win_idx,"num":num_idx if num_idx is not None else -1,"jockey":jockey_idx if jockey_idx is not None else -1}
    return None, {}

def parse_odds_table(soup: BeautifulSoup) -> Tuple[List[Dict[str,float]], Optional[str], Optional[str]]:
    venue_race = (soup.find("h1").get_text(strip=True) if soup.find("h1") else None)
    nowtime = soup.select_one(".withUpdate .nowTime") or soup.select_one(".nowTime")
    now_label = nowtime.get_text(strip=True) if nowtime else None
    table, idx = _find_popular_odds_table(soup)
    if not table: return [], venue_race, now_label
    pop_idx=idx["pop"]; win_idx=idx["win"]; num_idx=idx.get("num",-1); jockey_idx=idx.get("jockey",-1)
    horses=[]; body=table.find("tbody") or table
    for tr in body.find_all("tr"):
        tds=tr.find_all(["td","th"])
        if len(tds)<=max(pop_idx,win_idx): continue
        pop_txt=tds[pop_idx].get_text(strip=True)
        if not pop_txt.isdigit(): continue
        pop=int(pop_txt)
        if not (1<=pop<=30): continue
        odds=_as_float(tds[win_idx].get_text(" ", strip=True))
        if odds is None: continue
        num=None
        if 0<=num_idx<len(tds): num=_as_int(tds[num_idx].get_text(" ", strip=True))
        jockey=None
        if 0<=jockey_idx<len(tds):
            jt=tds[jockey_idx].get_text(" ", strip=True)
            jraw = re.split(r"[ï¼ˆ( ]", jt)[0].strip() if jt else None
            jockey = jraw if jraw else None
        rec={"pop":pop, "odds":float(odds)}
        if num is not None: rec["num"]=num
        if jockey: rec["jockey"]=jockey
        horses.append(rec)
    uniq={}
    for h in sorted(horses, key=lambda x:x["pop"]): uniq[h["pop"]]=h
    horses=[uniq[k] for k in sorted(uniq.keys())]
    return horses, venue_race, now_label

# === é¨æ‰‹åã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° & å‡ºé¦¬è¡¨ã‹ã‚‰è£œå®Œ ===
def _clean_jockey_name(s: str) -> str:
    if not s: return ""
    s = re.sub(r"\(.*?\)", "", s)
    s = re.sub(r"[â–²â–³â˜†â˜…â—‡â—†âŠ™â—â—‹â—¯â—‰âšªï¸ï¼‹+ï¼Š*]", "", s)
    s = re.sub(r"\d+(?:\.\d+)?\s*(?:kg|æ–¤)?", "", s)
    s = s.replace("æ–¤é‡","")
    return s.strip()

def fetch_jockey_map_from_card(race_id: str) -> Dict[int, str]:
    urls = [
        f"https://keiba.rakuten.co.jp/race_card/RACEID/{race_id}",
        f"https://keiba.rakuten.co.jp/race_card/list/RACEID/{race_id}",
    ]
    result: Dict[int,str] = {}
    for url in urls:
        try:
            soup = BeautifulSoup(fetch(url), "lxml")
        except Exception:
            continue
        for table in soup.find_all("table"):
            thead = table.find("thead")
            if not thead: continue
            headers = [_clean(th.get_text()) for th in thead.find_all(["th","td"])]
            if not headers: continue
            num_idx = next((i for i,h in enumerate(headers) if "é¦¬ç•ª" in h), -1)
            jockey_idx = next((i for i,h in enumerate(headers) if any(k in h for k in ("é¨æ‰‹","é¨æ‰‹å"))), -1)
            if num_idx < 0 or jockey_idx < 0: continue
            body = table.find("tbody") or table
            for tr in body.find_all("tr"):
                tds = tr.find_all(["td","th"])
                if len(tds) <= max(num_idx, jockey_idx): continue
                num = _as_int(tds[num_idx].get_text(" ", strip=True))
                jtx = tds[jockey_idx].get_text(" ", strip=True)
                if num is None or not jtx: continue
                name = _clean_jockey_name(re.split(r"[ï¼ˆ(]", jtx)[0])
                if name:
                    result[num] = name
            if result:
                return result
    return result

def _enrich_horses_with_jockeys(horses: List[Dict[str,float]], race_id: str) -> None:
    need = any((h.get("jockey") is None) and isinstance(h.get("num"), int) for h in horses)
    if not need: return
    num2jockey = fetch_jockey_map_from_card(race_id)
    if not num2jockey: return
    for h in horses:
        if not h.get("jockey") and isinstance(h.get("num"), int):
            name = num2jockey.get(h["num"])
            if name:
                h["jockey"] = name

def check_tanfuku_page(race_id: str) -> Optional[Dict]:
    url = f"https://keiba.rakuten.co.jp/odds/tanfuku/RACEID/{race_id}"
    html = fetch(url)
    soup = BeautifulSoup(html, "lxml")
    horses, venue_race, now_label = parse_odds_table(soup)
    if not horses: return None
    if not venue_race: venue_race="åœ°æ–¹ç«¶é¦¬"
    _enrich_horses_with_jockeys(horses, race_id)
    return {"race_id": race_id, "url": url, "horses": horses, "venue_race": venue_race, "now": now_label or ""}

# ========= ç™ºèµ°æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ =========
def fallback_post_time_for_rid(rid: str) -> Optional[Tuple[datetime, str, str]]:
    def _from_list_page() -> Optional[Tuple[datetime,str,str]]:
        url=f"https://keiba.rakuten.co.jp/race_card/list/RACEID/{rid}"
        soup=BeautifulSoup(fetch(url),"lxml")
        a=soup.find("a", href=re.compile(rf"/RACEID/{rid}"))
        if not a: return None
        host=None
        for parent in a.parents:
            if isinstance(parent, Tag) and parent.name in ("tr","li","div","section","article"):
                host=parent; break
        host=host or a
        hhmm,reason=_find_time_nearby(host)
        if not hhmm:
            sibs=[n for n in host.find_all_next(limit=6) if isinstance(n, Tag)]
            text=" ".join([n.get_text(" ", strip=True) for n in sibs])
            if not IGNORE_NEAR_PAT.search(text):
                got=_norm_hhmm_from_text(text)
                if got:
                    hh,mm,why=got
                    hhmm,reason=f"{hh:02d}:{mm:02d}", f"sibling:text/{why}"
        if not hhmm: return None
        hh,mm=map(int, hhmm.split(":")); dt=_make_dt_from_hhmm(rid, hh, mm)
        return (dt, f"list-anchor/{reason}", url) if dt else None

    def _from_tanfuku_page() -> Optional[Tuple[datetime,str,str]]:
        url=f"https://keiba.rakuten.co.jp/odds/tanfuku/RACEID/{rid}"
        soup=BeautifulSoup(fetch(url),"lxml")
        for key in ("ç™ºèµ°","ç™ºèµ°æ™‚åˆ»","ç™ºèµ°äºˆå®š","ç™ºé€","å‡ºèµ°"):
            for node in soup.find_all(string=re.compile(key)):
                el=getattr(node,"parent",None) or soup
                container=el
                for parent in el.parents:
                    if isinstance(parent, Tag) and parent.name in ("div","section","article","li"):
                        container=parent; break
                chunks=[]
                try: chunks.append(container.get_text(" ", strip=True))
                except: pass
                for sub in container.find_all(True, limit=6):
                    try: chunks.append(sub.get_text(" ", strip=True))
                    except: pass
                near=" ".join(chunks)
                if IGNORE_NEAR_PAT.search(near): continue
                got=_norm_hhmm_from_text(near)
                if got:
                    hh,mm,why=got; dt=_make_dt_from_hhmm(rid, hh, mm)
                    if dt: return dt, f"tanfuku-label/{key}/{why}", url
        return None

    try:
        got=_from_list_page()
        if got: return got
    except Exception as e:
        logging.warning("[WARN] fallback(list)å¤±æ•— rid=%s: %s", rid, e)
    try:
        got=_from_tanfuku_page()
        if got: return got
    except Exception as e:
        logging.warning("[WARN] fallback(tanfuku)å¤±æ•— rid=%s: %s", rid, e)
    return None

# ========= RACEID åˆ—æŒ™ =========
def list_raceids_today_ticket(ymd: str) -> List[str]:
    url=f"https://keiba.rakuten.co.jp/race_card/list/RACEID/{ymd}0000000000"
    soup=BeautifulSoup(fetch(url),"lxml")
    ids=_extract_raceids_from_soup(soup)
    logging.info(f"[INFO] Rakuten#1 æœ¬æ—¥ã®ç™ºå£²æƒ…å ±: {len(ids)}ä»¶")
    return ids

def list_raceids_from_card_lists(ymd: str, ymd_next: str) -> List[str]:
    urls=[
        f"https://keiba.rakuten.co.jp/race_card/list/RACEID/{ymd}0000000000",
        f"https://keiba.rakuten.co.jp/race_card/list/RACEID/{ymd_next}0000000000",
    ]
    rids=[]
    for u in urls:
        try:
            soup=BeautifulSoup(fetch(u),"lxml")
            rids.extend(_extract_raceids_from_soup(soup))
        except Exception as e:
            logging.warning(f"[WARN] å‡ºé¦¬è¡¨ä¸€è¦§ã‚¹ã‚­ãƒ£ãƒ³å¤±æ•—: {e} ({u})")
    rids=sorted(set(rids))
    logging.info(f"[INFO] Rakuten#2 å‡ºé¦¬è¡¨ä¸€è¦§: {len(rids)}ä»¶")
    return rids

# ========= çª“åˆ¤å®š =========
def is_within_window(post_time: datetime, now: datetime) -> bool:
    if CUTOFF_OFFSET_MIN>0 and now >= (post_time - timedelta(minutes=CUTOFF_OFFSET_MIN)):
        return False
    win_start=post_time - timedelta(minutes=WINDOW_BEFORE_MIN)
    win_end  =post_time + timedelta(minutes=WINDOW_AFTER_MIN)
    return (win_start <= now <= win_end)

# ========= LINE =========
def push_line_text(user_id: str, token: str, text: str, timeout=8, retries=1):
    headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    payload={"to": user_id, "messages":[{"type":"text","text": text}]}
    for attempt in range(retries+1):
        try:
            resp=requests.post(LINE_PUSH_URL, headers=headers, json=payload, timeout=timeout)
            if resp.status_code==200: return True, 200, resp.text
            if resp.status_code==429 and attempt<retries:
                wait=int(resp.headers.get("Retry-After","1")); time.sleep(max(wait,1)); continue
            return False, resp.status_code, resp.text
        except requests.RequestException as e:
            if attempt<retries: time.sleep(2); continue
            return False, None, str(e)

def notify_strategy_hit_to_many(message_text: str, targets: List[str]):
    if not NOTIFY_ENABLED: logging.info("[INFO] NOTIFY_ENABLED=0"); return False, None
    if DRY_RUN: logging.info("[DRY_RUN] é€šçŸ¥:\n%s", message_text); return False, None
    if not LINE_ACCESS_TOKEN: logging.error("[ERROR] LINE_ACCESS_TOKEN ä¸è¶³"); return False, None
    if not targets: logging.error("[ERROR] é€ä¿¡å…ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãªã—"); return False, None
    all_ok=True; last=None
    for uid in targets:
        ok, status, _ = push_line_text(uid, LINE_ACCESS_TOKEN, message_text)
        last=status
        if not ok: all_ok=False
        time.sleep(0.2)
    return all_ok, last

# ========= é€šçŸ¥ãƒ†ã‚­ã‚¹ãƒˆå…±é€š =========
_CIRCLED="â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨"
def _circled(n:int)->str: return _CIRCLED[n-1] if 1<=n<=9 else f"{n}."
def _extract_hhmm_label(s:str)->Optional[str]:
    got=_norm_hhmm_from_text(s)
    if not got: return None
    hh,mm,_=got; return f"{hh:02d}:{mm:02d}"
def _infer_pattern_no(strategy_text: str) -> int:
    if not strategy_text: return 0
    m=re.match(r"\s*([â‘ -â‘¨])", strategy_text)
    if m: return _CIRCLED.index(m.group(1))+1
    m=re.match(r"\s*(\d+)", strategy_text)
    if m:
        try: return int(m.group(1))
        except: return 0
    return 0
def _strip_pattern_prefix(strategy_text: str) -> str:
    s=re.sub(r"^\s*[â‘ -â‘¨]\s*", "", strategy_text or "")
    s=re.sub(r"^\s*\d+\s*", "", s); return s.strip()
def _split_venue_race(venue_race: str) -> Tuple[str,str]:
    if not venue_race: return "åœ°æ–¹ç«¶é¦¬",""
    m=re.search(r"^\s*([^\s\d]+)\s*(\d{1,2}R)\b", venue_race)
    if m:
        venue=m.group(1); race=m.group(2)
        venue_disp = f"{venue}ç«¶é¦¬å ´" if "ç«¶é¦¬" not in venue else venue
        return venue_disp, race
    return venue_race, ""

def _parse_ticket_as_pops(ticket: str) -> List[int]:
    parts=[p.strip() for p in re.split(r"[-â†’>ã€œ~]", str(ticket)) if p.strip()]
    out=[]
    for p in parts:
        m=re.search(r"\d+", p)
        if m:
            try: out.append(int(m.group(0)))
            except: pass
    return out

def _map_pop_to_info(horses: List[Dict[str,float]]) -> Dict[int, Dict[str, Optional[float]]]:
    m={}
    for h in horses:
        try:
            p=int(h.get("pop"))
            num=h.get("num") if isinstance(h.get("num"), int) else None
            o=float(h.get("odds")) if h.get("odds") is not None else None
            j=h.get("jockey") or None
            m[p]={"umaban":num,"odds":o,"jockey":j}
        except: pass
    return m

def _tickets_pop_to_umaban(bets: List[str], horses: List[Dict[str,float]]) -> List[str]:
    pop2=_map_pop_to_info(horses)
    out=[]
    for b in bets:
        pops=_parse_ticket_as_pops(b)
        if not pops: out.append(b); continue
        nums=[]; ok=True
        for p in pops:
            n=pop2.get(p,{}).get("umaban")
            if n is None: ok=False; break
            nums.append(str(n))
        out.append("-".join(nums) if ok else b)
    return out

def _format_bets_with_rank(bets: List[str], horses: List[Dict[str,float]]) -> List[str]:
    pop2=_map_pop_to_info(horses)
    out=[]
    for bet in bets:
        pops=_parse_ticket_as_pops(bet)
        if not pops: out.append(bet); continue
        segs=[]
        for p in pops:
            info=pop2.get(p, {})
            n=info.get("umaban"); jk=info.get("jockey")
            r=jockey_rank_letter_by_name(jk) if jk else "â€”"
            segs.append(f"{p}ç•ªäººæ°—ï¼ˆ" + (f"é¦¬ç•ª {n}ï¼" if n is not None else "") + f"é¨æ‰‹ãƒ©ãƒ³ã‚¯{r}ï¼‰")
        out.append(" - ".join(segs))
    return out

# é€šçŸ¥æœ¬æ–‡ï¼ˆâ‘ â‘¡â‘£ å…±é€šï¼‰
def build_line_notification(pattern_no:int, venue:str, race_no:str, time_label:str, time_hm:str,
                            condition_text:str, bets:List[str], odds_timestamp_hm:Optional[str],
                            odds_url:str) -> str:
    title=f"ã€æˆ¦ç•¥{pattern_no if pattern_no>0 else ''}è©²å½“ãƒ¬ãƒ¼ã‚¹ç™ºè¦‹ğŸ’¡ã€‘".replace("æˆ¦ç•¥è©²å½“","æˆ¦ç•¥è©²å½“")
    lines=[title, f"â– ãƒ¬ãƒ¼ã‚¹ï¼š{venue} {race_no}ï¼ˆ{time_label} {time_hm}ï¼‰".strip(), f"â– æ¡ä»¶ï¼š{condition_text}", "", "â– è²·ã„ç›®ï¼š"]
    for i,bet in enumerate(bets,1): lines.append(f"{_circled(i)} {bet}")
    if odds_timestamp_hm: lines+=["", f"ğŸ“… ã‚ªãƒƒã‚ºæ™‚ç‚¹: {odds_timestamp_hm}"]
    lines+=["ğŸ”— ã‚ªãƒƒã‚ºè©³ç´°:", odds_url]
    return "\n".join(lines)

# â‘¢å°‚ç”¨
def build_line_notification_strategy3(strategy:Dict, venue:str, race_no:str, time_label:str, time_hm:str,
                                      odds_timestamp_hm:Optional[str], odds_url:str,
                                      horses:List[Dict[str,float]]) -> str:
    pop2=_map_pop_to_info(horses)
    axis=strategy.get("axis") or {}
    axis_num=axis.get("umaban") or (pop2.get(1,{}).get("umaban"))
    axis_odds=axis.get("odds") if axis.get("odds") is not None else pop2.get(1,{}).get("odds")
    axis_jockey=axis.get("jockey") or pop2.get(1,{}).get("jockey")
    axis_rank=f"é¨æ‰‹ãƒ©ãƒ³ã‚¯{jockey_rank_letter_by_name(axis_jockey)}" if axis_jockey else "é¨æ‰‹ãƒ©ãƒ³ã‚¯â€”"
    cands=strategy.get("candidates")
    if not cands:
        cands=[]
        for h in sorted(horses, key=lambda x:int(x.get("pop",999))):
            try:
                p=int(h.get("pop")); o=float(h.get("odds"))
                if p==1: continue
                if 10.0<=o<=20.0:
                    cands.append({"pop":p,"odds":o,"umaban":h.get("num"),"jockey":h.get("jockey")})
                    if len(cands)>=4: break
            except: pass
    tickets=strategy.get("tickets") or []
    if not tickets and axis_num:
        nums=[c.get("umaban") for c in cands if c.get("umaban") is not None]
        tks=[]
        for i in range(len(nums)):
            for j in range(len(nums)):
                if i==j: continue
                tks.append(f"{axis_num}-{nums[i]}-{nums[j]}")
        tickets=tks
    title="ã€æˆ¦ç•¥â‘¢è©²å½“ãƒ¬ãƒ¼ã‚¹ç™ºè¦‹ğŸ’¡ã€‘"
    cond_line="1ç•ªäººæ°— â‰¤2.0ã€2ç•ªäººæ°— â‰¥10.0ã€ç›¸æ‰‹ï¼å˜å‹10ã€œ20å€ï¼ˆæœ€å¤§4é ­ï¼‰"
    cands_sorted=sorted([c for c in cands if c.get("pop")], key=lambda x:x["pop"])
    n=len(cands_sorted); pts=n*(n-1) if n>=2 else 0
    def _cand_line(c:Dict)->str:
        jrank=f"ï¼é¨æ‰‹ãƒ©ãƒ³ã‚¯{jockey_rank_letter_by_name(c.get('jockey'))}" if c.get("jockey") else ""
        um=c.get("umaban","â€”"); od=f"{c.get('odds',0):.1f}å€" if c.get("odds") is not None else "â€”"
        return f"    ãƒ»{c['pop']}ç•ªäººæ°—ï¼ˆé¦¬ç•ª {um}ï¼{od}{jrank}ï¼‰"
    cand_lines="\n".join([_cand_line(c) for c in cands_sorted]) if cands_sorted else "    ãƒ»â€”"
    axis_str=f"1ç•ªäººæ°—ï¼ˆé¦¬ç•ª {axis_num if axis_num is not None else 'â€”'}" + (f"ï¼{axis_odds:.1f}å€" if axis_odds is not None else "") + f"ï¼{axis_rank}ï¼‰"
    lines=[title, f"â– ãƒ¬ãƒ¼ã‚¹ï¼š{venue} {race_no}ï¼ˆ{time_label} {time_hm}ï¼‰", f"â– æ¡ä»¶ï¼š{cond_line}",
           f"â– è²·ã„ç›®ï¼ˆ3é€£å˜ãƒ»1ç€å›ºå®šï¼‰ï¼š{', '.join(tickets) if tickets else 'â€”'}",
           f"  è»¸ï¼š{axis_str}", "  ç›¸æ‰‹å€™è£œï¼ˆ10ã€œ20å€ï¼‰ï¼š", f"{cand_lines}", f"  â†’ å€™è£œ {n}é ­ï¼åˆè¨ˆ {pts}ç‚¹"]
    if odds_timestamp_hm: lines += [f"\nğŸ“… ã‚ªãƒƒã‚ºæ™‚ç‚¹: {odds_timestamp_hm}"]
    lines += ["ğŸ”— ã‚ªãƒƒã‚ºè©³ç´°:", odds_url, "", "â€»ã‚ªãƒƒã‚ºã¯ç· åˆ‡ç›´å‰ã¾ã§å¤‰åŒ–ã—ã¾ã™", "â€»é¦¬åˆ¸çš„ä¸­ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ä½™è£•è³‡é‡‘ã§ã”è³¼å…¥ãã ã•ã„"]
    return "\n".join(lines)

# ========= ãƒ™ãƒƒãƒˆè¨˜éŒ² =========
def _bets_sheet_header() -> List[str]:
    return ["date","race_id","venue","race_no","strategy","bet_kind","tickets_umaban_csv","points","unit_stake","total_stake"]

def sheet_append_bet_record(date_ymd:str, race_id:str, venue:str, race_no:str,
                            strategy_no:int, bet_kind:str, tickets_umaban:List[str]):
    svc=_sheet_service()
    title=_resolve_sheet_title(svc, BETS_SHEET_TAB)
    values=_sheet_get_range_values(svc, title, "A:J")
    if not values:
        values=[_bets_sheet_header()]
    points=len(tickets_umaban)
    unit=UNIT_STAKE_YEN
    total=points*unit
    values.append([date_ymd, race_id, venue, race_no, str(strategy_no), bet_kind, ",".join(tickets_umaban), str(points), str(unit), str(total)])
    _sheet_update_range_values(svc, title, "A:J", values)

# ========= æ‰•æˆ»å–å¾—ï¼†æ—¥æ¬¡ã‚µãƒãƒª =========
_PAYOUT_KIND_KEYS = ["å˜å‹","è¤‡å‹","æ é€£","é¦¬é€£","ãƒ¯ã‚¤ãƒ‰","é¦¬å˜","ä¸‰é€£è¤‡","ä¸‰é€£å˜"]

def fetch_payoff_map(race_id:str) -> Dict[str, List[Tuple[str,int]]]:
    url=f"https://keiba.rakuten.co.jp/race/payoff/RACEID/{race_id}"
    html=fetch(url)
    soup=BeautifulSoup(html, "lxml")
    result: Dict[str, List[Tuple[str,int]]] = {}
    for kind in _PAYOUT_KIND_KEYS:
        blocks = soup.find_all(string=re.compile(kind))
        items: List[Tuple[str,int]] = []
        for b in blocks:
            box = getattr(b, "parent", None) or soup
            text = " ".join((box.get_text(" ", strip=True) or "").split())
            for m in re.finditer(r"(\d+(?:-\d+){0,2})\s*([\d,]+)\s*å††", text):
                comb = m.group(1)
                pay  = int(m.group(2).replace(",",""))
                items.append((comb, pay))
        if items:
            result[kind] = items
    return result

def _normalize_ticket_for_kind(ticket:str, kind:str) -> str:
    parts=[int(x) for x in ticket.split("-") if x.strip().isdigit()]
    if kind in ("é¦¬é€£","ä¸‰é€£è¤‡"):
        parts=sorted(parts)
    return "-".join(str(x) for x in parts)

def summarize_today_and_notify(targets: List[str]):
    svc=_sheet_service()
    title=_resolve_sheet_title(svc, BETS_SHEET_TAB)
    values=_sheet_get_range_values(svc, title, "A:J")
    if not values or values==[_bets_sheet_header()]:
        logging.info("[INFO] betsã‚·ãƒ¼ãƒˆã«å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãªã—"); return
    hdr=values[0]; rows=values[1:]
    today=now_jst().strftime("%Y%m%d")
    records=[r for r in rows if len(r)>=10 and r[0]==today]
    if not records:
        logging.info("[INFO] å½“æ—¥åˆ†ãªã—"); return

    per_strategy = { "1":{"races":0,"hits":0,"bets":0,"stake":0,"return":0},
                     "2":{"races":0,"hits":0,"bets":0,"stake":0,"return":0},
                     "3":{"races":0,"hits":0,"bets":0,"stake":0,"return":0},
                     "4":{"races":0,"hits":0,"bets":0,"stake":0,"return":0} }
    seen_race_strategy=set()

    for r in records:
        date_ymd, race_id, venue, race_no, strategy, bet_kind, t_csv, points, unit, total = r[:10]
        if (race_id, strategy) not in seen_race_strategy:
            seen_in_this = (race_id, strategy)
            seen_race_strategy.add(seen_in_this)
        tickets=[t for t in t_csv.split(",") if t]
        per_strategy[strategy]["races"] += 1
        per_strategy[strategy]["bets"]  += len(tickets)
        per_strategy[strategy]["stake"] += int(total)

        paymap = fetch_payoff_map(race_id)
        winners = { _normalize_ticket_for_kind(comb, bet_kind) : pay for (comb, pay) in paymap.get(bet_kind, []) }
        for t in tickets:
            norm=_normalize_ticket_for_kind(t, bet_kind)
            if norm in winners:
                per_strategy[strategy]["hits"]   += 1
                per_strategy[strategy]["return"] += winners[norm]

        time.sleep(0.2)

    total_stake=sum(v["stake"] for v in per_strategy.values())
    total_return=sum(v["return"] for v in per_strategy.values())

    def pct(n,d): return f"{(100.0*n/d):.1f}%" if d>0 else "0.0%"

    lines=[]
    lines.append("ğŸ“Šã€æœ¬æ—¥ã®æ¤œè¨¼çµæœã€‘")
    lines.append(f"æ—¥ä»˜ï¼š{today[:4]}/{today[4:6]}/{today[6:]}")
    lines.append("")
    for k in ("1","2","3","4"):
        v=per_strategy[k]
        hit_rate = pct(v["hits"], max(v["bets"],1))
        roi      = pct(v["return"], max(v["stake"],1))
        lines.append(f"æˆ¦ç•¥{k}ï¼šè©²å½“{v['races']}ãƒ¬ãƒ¼ã‚¹ / è³¼å…¥{v['bets']}ç‚¹ / çš„ä¸­{v['hits']}ç‚¹")
        lines.append(f"ã€€ã€€ã€€çš„ä¸­ç‡ {hit_rate} / å›åç‡ {roi}")
    lines.append("")
    lines.append(f"åˆè¨ˆï¼šæŠ•è³‡ {total_stake:,}å†† / æ‰•æˆ» {total_return:,}å†† / å›åç‡ {pct(total_return, max(total_stake,1))}")

    notify_strategy_hit_to_many("\n".join(lines), targets)

# ========= ç›£è¦–æœ¬ä½“ï¼ˆä¸€å›å®Ÿè¡Œï¼‰ =========
def main():
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
    p=pathlib.Path(__file__).resolve()
    sha=hashlib.sha1(p.read_bytes()).hexdigest()[:12]
    logging.info(f"[BUILD] file={p} sha1={sha} v2025-08-13G")

    if KILL_SWITCH:
        logging.info("[INFO] KILL_SWITCH=True"); return

    # é€ä¿¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    try:
        targets=load_user_ids_from_simple_col()
        if not targets:
            fb=LINE_USER_IDS if LINE_USER_IDS else ([LINE_USER_ID] if LINE_USER_ID else [])
            targets=fb
    except Exception as e:
        logging.exception("[ERROR] usersã‚·ãƒ¼ãƒˆèª­è¾¼å¤±æ•—: %s", e)
        fb=LINE_USER_IDS if LINE_USER_IDS else ([LINE_USER_ID] if LINE_USER_ID else [])
        targets=fb
    logging.info("[INFO] é€ä¿¡å…ˆ=%d", len(targets))

    # ç¨¼åƒæ™‚é–“å†…ã§é€šå¸¸ç›£è¦–
    if within_operating_hours():
        try: notified=sheet_load_notified()
        except Exception as e:
            logging.exception("[ERROR] TTLãƒ­ãƒ¼ãƒ‰å¤±æ•—: %s", e); notified={}
        if DEBUG_RACEIDS:
            target_raceids=[rid for rid in DEBUG_RACEIDS if not PLACEHOLDER.search(rid)]
            post_time_map={}
        else:
            ymd=now_jst().strftime("%Y%m%d")
            ymd_next=(now_jst()+timedelta(days=1)).strftime("%Y%m%d")
            r1=list_raceids_today_ticket(ymd)
            r2=list_raceids_from_card_lists(ymd, ymd_next)
            target_raceids=sorted(set(r1)|set(r2))
            post_time_map=collect_post_time_map(ymd, ymd_next)
            target_raceids=[rid for rid in target_raceids if not PLACEHOLDER.search(rid)]

        hits=0; matches=0
        seen_in_this_run:set[str]=set()

        for rid in target_raceids:
            if rid in seen_in_this_run: continue
            now_ts=time.time()
            cd_ts=notified.get(f"{rid}:cd")
            if cd_ts and (now_ts-cd_ts)<NOTIFY_COOLDOWN_SEC: continue
            ts=notified.get(rid)
            if ts and (now_ts-ts)<NOTIFY_TTL_SEC: continue

            post_time=post_time_map.get(rid)
            if not post_time:
                got=fallback_post_time_for_rid(rid)
                if got: post_time, _, _ = got
                else: continue

            now=now_jst()
            if not is_within_window(post_time, now): continue

            meta=check_tanfuku_page(rid)
            if not meta: time.sleep(random.uniform(*SLEEP_BETWEEN)); continue

            horses=meta["horses"]
            if len(horses)<4: time.sleep(random.uniform(*SLEEP_BETWEEN)); continue

            hits+=1
            strategy=eval_strategy(horses, logger=logging)
            if not strategy:
                time.sleep(random.uniform(*SLEEP_BETWEEN)); continue
            matches+=1

            strategy_text=strategy.get("strategy","")
            pattern_no=_infer_pattern_no(strategy_text)
            condition_text=_strip_pattern_prefix(strategy_text) or strategy_text

            venue_disp, race_no=_split_venue_race(meta.get("venue_race",""))

            time_label="ç™ºèµ°" if CUTOFF_OFFSET_MIN==0 else "ç· åˆ‡"
            display_dt=post_time if CUTOFF_OFFSET_MIN==0 else (post_time - timedelta(minutes=CUTOFF_OFFSET_MIN))
            time_hm=display_dt.strftime("%H:%M")
            odds_hm=_extract_hhmm_label(meta.get("now",""))

            raw_tickets=strategy.get("tickets", [])
            if isinstance(raw_tickets, str):
                raw_tickets=[s.strip() for s in raw_tickets.split(",") if s.strip()]

            if str(strategy_text).startswith("â‘¢"):
                message=build_line_notification_strategy3(strategy, venue_disp, race_no, time_label, time_hm, odds_hm, meta["url"], horses)
                tickets_umaban = strategy.get("tickets", [])
                bet_kind = STRATEGY_BET_KIND.get("3", "ä¸‰é€£å˜")
            else:
                pretty=_format_bets_with_rank(raw_tickets, horses)
                message=build_line_notification(pattern_no, venue_disp, race_no, time_label, time_hm, condition_text, pretty, odds_hm, meta["url"])
                tickets_umaban=_tickets_pop_to_umaban(raw_tickets, horses)
                bet_kind = STRATEGY_BET_KIND.get(str(pattern_no), "ä¸‰é€£å˜")

            # é€ä¿¡
            sent_ok, http_status = notify_strategy_hit_to_many(message, targets)

            # â˜…é€šçŸ¥ãƒ­ã‚°ï¼ˆappend_notify_logï¼‰ã«è¿½è¨˜ï¼šé€ä¿¡æˆåŠŸæ™‚ã®ã¿
            if sent_ok:
                try:
                    append_notify_log({
                        'date_jst': jst_today_str(),
                        'race_id': rid,
                        'strategy': str(pattern_no),
                        'stake': len(tickets_umaban) * UNIT_STAKE_YEN,
                        'bets_json': json.dumps(tickets_umaban, ensure_ascii=False),
                        'notified_at': jst_now(),
                        'jockey_ranks': "/".join([
                            jockey_rank_letter_by_name(h.get("jockey")) if h.get("jockey") else "â€”"
                            for h in horses[:3]  # ä¸Šä½3äººæ°—
                        ]),
                    })
                except Exception as e:
                    logging.exception("[WARN] append_notify_logå¤±æ•—: %s", e)

            now_epoch=time.time()
            if sent_ok:
                try:
                    sheet_upsert_notified(rid, now_epoch, note=f"{meta['venue_race']} {post_time:%H:%M}")
                except Exception as e:
                    logging.exception("[ERROR] TTLæ›´æ–°å¤±æ•—: %s", e)
                seen_in_this_run.add(rid)
                try:
                    ymd=now_jst().strftime("%Y%m%d")
                    sheet_append_bet_record(ymd, rid, venue_disp, race_no, pattern_no, bet_kind, tickets_umaban or [])
                except Exception as e:
                    logging.exception("[ERROR] betsè¨˜éŒ²å¤±æ•—: %s", e)
            elif http_status==429:
                try:
                    key_cd=f"{rid}:cd"; sheet_upsert_notified(key_cd, now_epoch, note=f"429 cooldown {meta['venue_race']} {post_time:%H:%M}")
                except Exception as e:
                    logging.exception("[ERROR] CDæ›´æ–°å¤±æ•—: %s", e)

            time.sleep(random.uniform(*SLEEP_BETWEEN))

        logging.info(f"[INFO] HITS={hits} / MATCHES={matches}")

    # çµ‚æ¥­å¾Œã«ã‚µãƒãƒª
    try:
        if now_jst().hour >= END_HOUR:
            summarize_today_and_notify(targets)
    except Exception as e:
        logging.exception("[ERROR] æ—¥æ¬¡ã‚µãƒãƒªé€ä¿¡å¤±æ•—: %s", e)

    logging.info("[INFO] ã‚¸ãƒ§ãƒ–çµ‚äº†")

# ========= å¸¸é§ãƒ«ãƒ¼ãƒ— =========
def run_watcher_forever(interval_sec: int = int(os.getenv("WATCHER_INTERVAL_SEC", "60"))):
    """å†…éƒ¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‹ã‚‰ã‚‚å‘¼ã¹ã‚‹å¸¸é§ãƒ«ãƒ¼ãƒ—"""
    logging.info(f"[BOOT] run_watcher_forever(interval={interval_sec}s)")
    while True:
        try:
            main()
        except Exception as e:
            logging.exception("[FATAL] watcherãƒ«ãƒ¼ãƒ—ä¾‹å¤–: %s", e)
        time.sleep(interval_sec)